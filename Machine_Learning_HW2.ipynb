{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Machine_Learning_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tVPnSDv1WIc2YgmG59mADzhOprzsrtcm",
      "authorship_tag": "ABX9TyM1fqy+A9aKV2odPCliGdGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhatta1234/machineLearningAssignment/blob/main/Machine_Learning_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXiq6w16OPxJ"
      },
      "source": [
        "# **Loading essential modules and device declaration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUmcdJVIUmoC"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import time\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sc1S1PzxQi_"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3fAp9-GOhZN"
      },
      "source": [
        "# **Loading Data from CSV** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGqgfX07UsxV"
      },
      "source": [
        "data_path = \"drive/MyDrive/data/\"\n",
        "train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n",
        "                        delimiter=\",\")\n",
        "test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
        "                       delimiter=\",\") "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbO88yLugA5y"
      },
      "source": [
        "# **MNIST CNN Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfuSlhr8untH"
      },
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s76y6Vp1gEQS"
      },
      "source": [
        "image_size = 28 # width and length\n",
        "image_pixels = image_size * image_size\n",
        "\n",
        "# Normalize the pixels range from [0 255] to [0.01, 1]. \n",
        "# To avoid 0 values as inputs, each pixel is multiplied by 0.99 / 255, and then adding 0.01.\n",
        "train_imgs = (np.asfarray(train_data[:, 1:]) * 0.99 / 255 + 0.01)\n",
        "test_imgs = (np.asfarray(test_data[:, 1:]) * 0.99 / 255 + 0.01)\n",
        "\n",
        "# Reshaping all the images to (1,28,28) for CNN input. 1 is the number of input channel and (28,28) is the size of the image\n",
        "train_imgs = train_imgs.reshape(len(train_imgs),1,28,28)\n",
        "test_imgs = test_imgs.reshape(len(test_imgs),1,28,28)\n",
        "\n",
        "\n",
        "# All the labels\n",
        "train_labels = np.asfarray(train_data[:, :1])\n",
        "test_labels = np.asfarray(test_data[:, :1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANvFX_SWutBf"
      },
      "source": [
        "### Custom DataReader\n",
        "\n",
        "Implementation adapted from : pytorch forums\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPb5Rbhnul1w"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "      \n",
        "        self.data = torch.from_numpy(data).float()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN41g4BavSoj"
      },
      "source": [
        "### Data Loader preparation for Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8NEYGmvRIp"
      },
      "source": [
        "train_dataset = MyDataset(train_imgs, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,shuffle=True)\n",
        "\n",
        "test_dataset = MyDataset(test_imgs,test_labels)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEWRXzkwWhy"
      },
      "source": [
        "### Model, optimizer and Loss Function Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuSol7TUvcF1"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(CNN,self).__init__()\n",
        "\n",
        "    self.conv_stack1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            )\n",
        "\n",
        "    self.conv_stack2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "            )\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 800,out_features=256)\n",
        "    self.fc2 = nn.Linear(in_features = 256, out_features=10)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    outp = self.conv_stack1(x)\n",
        "    outp = self.conv_stack2(outp)\n",
        "\n",
        "    outp = outp.reshape(outp.size(0), -1)\n",
        "\n",
        "    outp = self.fc1(outp)\n",
        "\n",
        "    return self.fc2(outp)\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mNXlrFHx-L-",
        "outputId": "62dade39-3e97-4dda-b34f-a04742f75da0"
      },
      "source": [
        "model_CNN = CNN()\n",
        "\n",
        "#Sending model to GPU if available\n",
        "model_CNN.to(device)\n",
        "\n",
        "print(model_CNN)\n",
        "\n",
        "\n",
        "print(summary(model_CNN,input_size=(1,28,28)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv_stack1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv_stack2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=800, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 30, 30]             160\n",
            "              ReLU-2           [-1, 16, 30, 30]               0\n",
            "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 32, 5, 5]               0\n",
            "            Linear-7                  [-1, 256]         205,056\n",
            "            Linear-8                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 212,426\n",
            "Trainable params: 212,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.38\n",
            "Params size (MB): 0.81\n",
            "Estimated Total Size (MB): 1.19\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWdVCNFVwbUP"
      },
      "source": [
        "# Loss function declaration\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer Declaration\n",
        "\n",
        "optimizer = torch.optim.Adam(model_CNN.parameters(),lr = 0.001)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1IvhkPYyR_2"
      },
      "source": [
        "##**Training Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqLO6oENwcUw",
        "outputId": "b2a1ddd1-0827-4535-9a6a-09c9ce7f85ab"
      },
      "source": [
        "start_time = time.time()\n",
        "epochs = 61\n",
        "batch_size = 64\n",
        "\n",
        "loss_training = []\n",
        "accuracy_training = []\n",
        "\n",
        "model_CNN.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  accuracy = 0\n",
        "  loss_train = 0\n",
        "\n",
        "  for images,labels in iter(train_loader): \n",
        "\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model_CNN(images)\n",
        "    \n",
        "    loss = criterion(output,labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_train += loss.item()/ batch_size\n",
        "\n",
        "    max_element, max_indices = torch.max(output,dim=1)\n",
        "\n",
        "    accuracy += torch.sum(max_indices == labels)\n",
        "\n",
        "  loss_training.append(loss_train)\n",
        "  accuracy_per = accuracy / len(train_data) * 100\n",
        "  accuracy_training.append(accuracy_per)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"The loss in {}-th epoch is {}. Accuracy = {:.3f}%\".format(epoch,loss_train,accuracy_per))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(end_time-start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss in 0-th epoch is 2.751743712455209. Accuracy = 94.300%\n",
            "The loss in 10-th epoch is 0.26623753665575123. Accuracy = 99.415%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi6vN0TzxAA7"
      },
      "source": [
        "### Loss and Accuracy during Training Visulization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqFnvLlLwl3J"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (6.4,4.8)\n",
        "\n",
        "# Loss over training visulization\n",
        "x = np.arange(len(loss_training)) + 1\n",
        "plt.xlabel(\"Number of Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Change of Loss with increasing epoch\")\n",
        "plt.plot(x,loss_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8PG9-u3ybaK"
      },
      "source": [
        "# Accuracy over training visulization\n",
        "x = np.arange(len(loss_training)) + 1\n",
        "plt.xlabel(\"Number of Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(x,accuracy_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY4PPom4yYkn"
      },
      "source": [
        "## **Testing Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6odpGXZqwp4U"
      },
      "source": [
        "all_label = (torch.tensor([],dtype=torch.int64)).to(device)\n",
        "pred_label = (torch.tensor([],dtype=torch.int64)).to(device)\n",
        "\n",
        "loss_test = 0\n",
        "accuracy_test = 0\n",
        "\n",
        "\n",
        "model_CNN.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  \n",
        "  for images,labels in iter(test_loader):\n",
        "\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model_CNN(images)\n",
        "    loss = criterion(output,labels)\n",
        "\n",
        "    loss_test += loss.item()/ batch_size\n",
        "\n",
        "    _, max_indices = torch.max(output,dim=1)\n",
        "\n",
        "    labels = torch.squeeze(labels)\n",
        "\n",
        "    all_label = torch.cat((all_label,labels),dim=0)\n",
        "    pred_label = torch.cat((pred_label,max_indices),dim=0)\n",
        "\n",
        "    accuracy_test += torch.sum(max_indices == labels)\n",
        "\n",
        "\n",
        "accuracy_per = accuracy_test / len(test_data) * 100 \n",
        "print(\"The loss in test data is : {} Accuracy = {:.3f}%\".format(loss_test,accuracy_per))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodtVWW1wsEL"
      },
      "source": [
        "# Self Defined Confusion matrix calculation\n",
        "\n",
        "confusion_matrix = torch.zeros(10,10,dtype= torch.int64)\n",
        "val = torch.stack((all_label,pred_label),dim = 1)\n",
        "for i in val:\n",
        "  act,pred = i.tolist()\n",
        "  confusion_matrix[act,pred] = confusion_matrix[act,pred] + 1\n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCcobZjk_Jfg"
      },
      "source": [
        "## **Model Statistics and Confusion Matrix using Sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPeoHFPywvtZ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import numpy as np\n",
        "\n",
        "# Sending all the labels data to cpu and converting it to numpy\n",
        "labels = all_label.cpu().numpy()\n",
        "predictions = pred_label.cpu().numpy()\n",
        "\n",
        "#print(f1_score(labels,predictions,average='macro'))\n",
        "cm = confusion_matrix(labels,predictions)\n",
        "\n",
        "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "\n",
        "recall = np.mean(recall)\n",
        "precision = np.mean(precision)\n",
        "\n",
        "print(\"{:.5f}\".format(recall))\n",
        "print(\"{:.5f}\".format(precision))\n",
        "\n",
        "f1_score = (2 * precision * recall) / (precision + recall)\n",
        "print(\"{:.5f}\".format(f1_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6CkyKgC-_0H"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "recall_val = recall_score(labels,predictions,average=None)\n",
        "precision_val = precision_score(labels,predictions,average=None)\n",
        "f1_val = f1_score(labels,predictions,average=None)\n",
        "\n",
        "val = list(map(list, zip(precision_val,recall_val,f1_val)))\n",
        "\n",
        "print(tabulate(val, headers=[\"Class\",\"Precision\",\"Recall\", \"F1-Score\"],tablefmt=\"github\",showindex=\"always\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkqePwc6wwg9"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
        "labels_plot = np.arange(10)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels=labels_plot)\n",
        "disp.plot(cmap = 'inferno', values_format='d')\n",
        "plt.title(\"Display of Confusion Matrix\\n\",size = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwzLXP5_O5Ar"
      },
      "source": [
        "# **MNIST MLP implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmurG-WKPmOq"
      },
      "source": [
        "### Data preprocessing and demo image displays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCG84rfZbjv_"
      },
      "source": [
        "image_size = 28 # width and length\n",
        "image_pixels = image_size * image_size\n",
        "\n",
        "# Normalize the pixels range from [0 255] to [0.01, 1]. \n",
        "# To avoid 0 values as inputs, each pixel is multiplied by 0.99 / 255, and then adding 0.01.\n",
        "train_imgs = np.asfarray(train_data[:, 1:]) * 0.99 / 255 + 0.01\n",
        "test_imgs = np.asfarray(test_data[:, 1:]) * 0.99 / 255 + 0.01\n",
        "\n",
        "train_labels = np.asfarray(train_data[:, :1])\n",
        "test_labels = np.asfarray(test_data[:, :1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l73_VnNQbs8U"
      },
      "source": [
        "num_display = 32\n",
        "\n",
        "for i in range(num_display):\n",
        "    img = train_imgs[i].reshape((image_size,image_size))\n",
        "    label = train_labels[i][0]\n",
        "    if i % 8 == 0:\n",
        "      plt.figure(figsize=(16, 4))\n",
        "    plt.subplot(1, 8, i % 8 + 1)\n",
        "    plt.imshow(img,cmap='Greys')\n",
        "    plt.title(\"True label = {}\".format(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOVNigfJP68n"
      },
      "source": [
        "### Data Loader preparation for Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3wv-GBNQFYy"
      },
      "source": [
        "batch_size = 64\n",
        "shuffle = True\n",
        "\n",
        "# DataLoader for Train Data\n",
        "\n",
        "# concatenating images with their respective labels across column \n",
        "# Each row is long vector with first element as label and rest for image representation\n",
        "\n",
        "train_data = np.concatenate((train_labels,train_imgs),axis=1)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,shuffle=shuffle)\n",
        "\n",
        "\n",
        "# DataLoader for Test Data\n",
        "\n",
        "test_data = np.concatenate((test_labels,test_imgs),axis=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,shuffle=shuffle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN9DIls5R-q3"
      },
      "source": [
        "### Model, optimizer and Loss Function Declaration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0dcNTOsXctP"
      },
      "source": [
        "# Dynamic model implementation for MLP\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel,out_channel,num_hidden_layers):\n",
        "\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.num_hidden_layers = num_hidden_layers\n",
        "\n",
        "      self.hiddenfc = nn.ModuleList()\n",
        "\n",
        "      for i in range(num_hidden_layers):\n",
        "        \n",
        "        ## Reducing the feature size by half in each subsequent hidden layer\n",
        "        self.hiddenfc.append(nn.Linear( in_channel//(2**i), in_channel//(2**(i+1))))\n",
        "\n",
        "      # final hidden layer to ouput layer\n",
        "      self.outputfc = nn.Linear(in_channel//(2**(i+1)),out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      for layers in self.hiddenfc:\n",
        "        x = F.relu(layers(x))\n",
        "      \n",
        "      x = self.outputfc(x)\n",
        "      \n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqg5EY3xSPoK"
      },
      "source": [
        "model = Net(784,10,2)\n",
        "\n",
        "# Sending model to GPU is available\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n",
        "print(\"\\n The model summary and number of parameters required is shown below: \\n\")\n",
        "print(summary(model,input_size = (64,1,784)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsKsiW2BO--r"
      },
      "source": [
        "# Loss function declaration\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer Declaration\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJbYw-LmU125"
      },
      "source": [
        "##**Training Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P25eD--qRR3U"
      },
      "source": [
        "start_time = time.time()\n",
        "epochs = 61\n",
        "\n",
        "batch_size = 64\n",
        "loss_training = []\n",
        "accuracy_training = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  accuracy = 0\n",
        "  loss_train = 0\n",
        "\n",
        "  for i in iter(train_loader): \n",
        "\n",
        "    label = torch.tensor(i[:,:1],dtype=torch.long)\n",
        "    label = torch.reshape(label,(-1,))\n",
        "    label = label.to(device)\n",
        "\n",
        "    img = torch.tensor(i[:,1:]).float()\n",
        "    img = img.to(device)\n",
        "\n",
        "    # Optimizer accumulates value so set zero for each iteration   \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(img)\n",
        "    loss = criterion(output,label)\n",
        "\n",
        "    # Backprop step\n",
        "    loss.backward()\n",
        "\n",
        "    # Stepping in the opposite direction of gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_train += loss.item()/ batch_size\n",
        "\n",
        "    max_element, max_indices = torch.max(output,dim=1)\n",
        "\n",
        "    accuracy += torch.sum(max_indices == label)\n",
        "\n",
        "  loss_training.append(loss_train)\n",
        "  accuracy_per = accuracy / len(train_data) * 100 \n",
        "  accuracy_training.append(accuracy_per)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"The loss in {}-th epoch is {}. Accuracy = {:.3f}%\".format(epoch,loss_train,accuracy_per))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"\\nTime taken to finish the training with {} epoch is {:.3f} seconds\".format(epochs,end_time-start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRRpcqFqVod9"
      },
      "source": [
        "### Loss and Accuracy during Training Visulization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtTFPrF84QS"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (6.4,4.8)\n",
        "\n",
        "# Loss over training visulization\n",
        "x = np.arange(len(loss_training)) + 1\n",
        "plt.xlabel(\"Number of Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Change of Loss with increasing epoch\")\n",
        "plt.plot(x,loss_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLn5aS0BVvE5"
      },
      "source": [
        "# Accuracy over training visulization\n",
        "x = np.arange(len(loss_training)) + 1\n",
        "plt.xlabel(\"Number of Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(x,accuracy_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXIEOo8tfBWq"
      },
      "source": [
        "## **Testing Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO-1C2a_DCsO"
      },
      "source": [
        "all_label = (torch.tensor([],dtype=torch.int64)).to(device)\n",
        "pred_label = torch.tensor([],dtype=torch.int64).to(device)\n",
        "\n",
        "loss_test = 0\n",
        "accuracy_test = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  \n",
        "  for i in iter(test_loader):\n",
        "    \n",
        "    label = torch.tensor(i[:,:1],dtype=torch.long)\n",
        "    label = torch.reshape(label,(-1,))\n",
        "    label = label.to(device)\n",
        "\n",
        "    img = torch.tensor(i[:,1:]).float()\n",
        "    img = img.to(device)\n",
        "\n",
        "    output = model(img)\n",
        "    loss = criterion(output,label)\n",
        "\n",
        "    loss_test += loss.item()/ batch_size\n",
        "\n",
        "    _, max_indices = torch.max(output,dim=1)\n",
        "\n",
        "    label = torch.squeeze(label)\n",
        "\n",
        "    all_label = torch.cat((all_label,label),dim=0)\n",
        "    pred_label = torch.cat((pred_label,max_indices),dim=0)\n",
        "\n",
        "    accuracy_test += torch.sum(max_indices == label)\n",
        "\n",
        "\n",
        "accuracy_per = accuracy_test / len(test_data) * 100 \n",
        "print(\"The loss in test data is : {} Accuracy = {:.3f}%\".format(loss_test,accuracy_per))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXKfRTZnfKJt"
      },
      "source": [
        "### Self Defined Confusion Matrix Display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr9JR7ZdxWce"
      },
      "source": [
        "# Self Defined Confusion matrix calculation\n",
        "confusion_matrix = torch.zeros(10,10,dtype= torch.int64)\n",
        "val = torch.stack((all_label,pred_label),dim = 1)\n",
        "for i in val:\n",
        "  act,pred = i.tolist()\n",
        "  confusion_matrix[act,pred] = confusion_matrix[act,pred] + 1\n",
        "  \n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mEOXmo0fRxh"
      },
      "source": [
        "## **Model Statistics and Confusion Matrix using Sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okSMJ0-Rgk6R"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import numpy as np\n",
        "\n",
        "labels = all_label.cpu().numpy()\n",
        "predictions = pred_label.cpu().numpy()\n",
        "\n",
        "cm = confusion_matrix(labels,predictions)\n",
        "\n",
        "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "\n",
        "recall = np.mean(recall)\n",
        "precision = np.mean(precision)\n",
        "\n",
        "print(\"Recall Score: {:.5f}\".format(recall))\n",
        "print(\"\\nPrecision Score: {:.5f}\".format(precision))\n",
        "\n",
        "f1_score = (2 * precision * recall) / (precision + recall)\n",
        "print(\"\\nF1- Score: {:.5f}\".format(f1_score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQEATV_0p2V"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "recall_val = recall_score(labels,predictions,average=None)\n",
        "precision_val = precision_score(labels,predictions,average=None)\n",
        "f1_val = f1_score(labels,predictions,average=None)\n",
        "\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "val = list(map(list, zip(precision_val,recall_val,f1_val)))\n",
        "\n",
        "\n",
        "print(tabulate(val, headers=[\"Class\",\"Precision\",\"Recall\", \"F1-Score\"],tablefmt=\"github\",showindex=\"always\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iantPSRcrmwy"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
        "labels_plot = np.arange(10)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels=labels_plot)\n",
        "disp.plot(cmap = 'inferno', values_format='d')\n",
        "plt.title(\"Display of Confusion Matrix\\n\",size = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}